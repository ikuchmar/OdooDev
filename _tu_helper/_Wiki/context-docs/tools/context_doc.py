#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Context Docs Viewer ‚Äî –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä—â–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑ Markdown —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º.
–û–¥–∏–Ω —Ñ–∞–π–ª. –¢–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞. Python 3.8+.

–ó–ê–ß–ï–ú –ù–£–ñ–ï–ù –°–ö–†–ò–ü–¢
- –£–¥–æ–±–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –ª–∏—á–Ω—É—é/–∫–æ–º–∞–Ω–¥–Ω—É—é –¥–æ–∫—É –≤ Markdown –≤ Git-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ (–ø–∞–ø–∫–∞ docs).
- –ë—ã—Å—Ç—Ä–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω—É–∂–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –ø–æ –∫–ª—é—á—É, –∞–ª–∏–∞—Å–∞–º, —Ç–æ–∫–µ–Ω–∞–º –∏ –¥–∞–∂–µ –Ω–µ—Ç–æ—á–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É (fuzzy).
- –°–º–æ—Ç—Ä–µ—Ç—å Markdown-—Ç–µ–∫—Å—Ç, –≤—ã–±–∏—Ä–∞—Ç—å –∏ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏, –æ—Ç–∫—Ä—ã–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π .md.

–ö–ê–ö –≠–¢–û –†–ê–ë–û–¢–ê–ï–¢
- –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–∫–∞–Ω–∏—Ä—É–µ–º ../docs (–Ω–∞ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ —Å–∫—Ä–∏–ø—Ç–∞).
- –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ .md (UTF-8, fallback cp1251), —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–µ–∫—Ü–∏–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º "## <–∫–ª—é—á>".
- –ü–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏:
    categories: –ö–∞—Ç–µ–≥–æ—Ä–∏—è 1 - –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è 2 - ...
    aliases: alias1, alias2; alias3 alias4
- –î–ª—è –∫–∞–∂–¥–æ–π —Å–µ–∫—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º:
    display_key, key (lowercase), tokens (—Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ [^a-z0-9_]),
    categories[], aliases[], file_path, start_line, markdown, code_blocks[].
- –í UI –¥–≤–∞ –¥–µ—Ä–µ–≤–∞ (–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –§–∞–π–ª—ã), —Å–ø—Ä–∞–≤–∞ Markdown –∏ –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏.
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∏—Å—Ç–æ—Ä–∏—è (–ù–∞–∑–∞–¥/–í–ø–µ—Ä—ë–¥), –∞–≤—Ç–æ–ø–æ–∏—Å–∫ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º.

–°–¢–†–£–ö–¢–£–†–ê –ö–û–î–ê:
1) –ò–º–ø–æ—Ä—Ç—ã
2) –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
3) –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ .md
4) –§—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ (—Ç–æ—á–Ω—ã–π/–∞–ª–∏–∞—Å—ã/–ø–æ–¥—Å—Ç—Ä–æ–∫–∞/—Ç–æ–∫–µ–Ω—ã/fuzzy)
5) –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤ –¥–ª—è UI (–∫–∞—Ç–µ–≥–æ—Ä–∏–∏, —Ñ–∞–π–ª—ã)
6) –£—Ç–∏–ª–∏—Ç—ã (–æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –≤ —Å–∏—Å—Ç–µ–º–µ, –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞, –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ)
7) –ö–ª–∞—Å—Å App_UI (–≤–µ—Å—å UI + —Ä–∞–±–æ—Ç–∞ —Å —É–∂–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏)
8) main()
9) if __name__ == '__main__': main()

–ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
- –ö–æ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ª–∏–Ω–µ–π–Ω—ã–π –∏ "–ø–ª–æ—Å–∫–∏–π": –º–∏–Ω–∏–º—É–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–µ–π, –ø–æ–¥—Ä–æ–±–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- –ù–∏–∫–∞–∫–∏—Ö –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
"""

# =========================
# 1) –ò–º–ø–æ—Ä—Ç—ã
# =========================
import os
import sys
import re
import difflib
import tkinter as tk
from tkinter import ttk, messagebox
import subprocess
from pathlib import Path
from typing import List, Dict, Tuple, Optional


# =========================
# 2) –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# =========================
# –ü–∞–ø–∫–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π ‚Äî –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ —Å–∫—Ä–∏–ø—Ç–∞
DEFAULT_DOCS_DIR = Path(__file__).resolve().parent.parent / "docs"

# –ü–∞–ø–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏
IGNORED_DIRS = {"node_modules", ".git", "site", ".venv", "venv", "__pycache__"}

# –†–µ–≥–µ–∫—Å—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
RE_SECTION_HEADER = re.compile(r"^\s*##\s+(?P<key>.+?)\s*$")  # —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å–µ–∫—Ü–∏–∏
RE_OPTIONAL_SEPARATOR = re.compile(r"^\s*(=+|-+)\s*$")        # —Å—Ç—Ä–æ–∫–∏ –∏–∑ ===== –∏–ª–∏ -----
RE_CATEGORIES = re.compile(r"^\s*categories\s*:\s*(?P<cats>.+?)\s*$", re.IGNORECASE)
RE_ALIASES = re.compile(r"^\s*aliases\s*:\s*(?P<als>.+?)\s*$", re.IGNORECASE)
RE_CODE_FENCE_START = re.compile(r"^\s*```(?P<lang>[\w\+\-\#\.]+)?\s*$")  # ```lang
RE_CODE_FENCE_END = re.compile(r"^\s*```\s*$")
RE_TOKEN_SPLIT = re.compile(r"[^a-z0-9_]+")

# –°–∏–º–≤–æ–ª—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–µ—Ä–µ–≤–µ —Ñ–∞–π–ª–æ–≤
ICON_FOLDER = "üìÅ "
ICON_FILE = "üìÑ "
SECTION_PREFIX = "¬ß "

# =========================
# 3) –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ .md
# =========================

def safe_read_text(path: Path) -> str:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞:
    1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º UTF-8
    2) –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –ø—Ä–æ–±—É–µ–º cp1251
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞.
    """
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="cp1251", errors="replace")


def normalize_key(s: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª—é—á–µ–π / –∞–ª–∏–∞—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞:
    - –ü—Ä–∏–≤–æ–¥–∏–º –∫ lowercase
    - –¢—Ä–∏–º–∏–º –ø—Ä–æ–±–µ–ª—ã
    """
    return (s or "").strip().lower()


def tokenize_key(key: str) -> List[str]:
    """
    –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∫–ª—é—á–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:
    - –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ª—é–±—ã–º —Å–∏–º–≤–æ–ª–∞–º –∫—Ä–æ–º–µ [a-z0-9_]
    - –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ
    –ü—Ä–∏–º–µ—Ä: "ul-ol-li" -> ["ul", "ol", "li"]
    """
    key_lc = normalize_key(key)
    parts = RE_TOKEN_SPLIT.split(key_lc)
    return [p for p in parts if p]


def parse_aliases(line_value: str) -> List[str]:
    """
    –†–∞–∑–±–æ—Ä —Å—Ç—Ä–æ–∫–∏ –∞–ª–∏–∞—Å–æ–≤:
    - –ê–ª–∏–∞—Å—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –∑–∞–ø—è—Ç—ã–º–∏, —Ç–æ—á–∫–∞–º–∏ —Å –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏
    - –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö (lowercase) –∞–ª–∏–∞—Å–æ–≤
    """
    if not line_value:
        return []
    # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: –∑–∞–ø—è—Ç–∞—è, —Ç–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π, –ø—Ä–æ–±–µ–ª—ã
    raw = re.split(r"[,\;\s]+", line_value)
    return [normalize_key(x) for x in raw if x.strip()]


def parse_categories(line_value: str) -> List[str]:
    """
    –†–∞–∑–±–æ—Ä —Å—Ç—Ä–æ–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π:
    - –§–æ—Ä–º–∞—Ç: "–ö–∞—Ç–µ–≥–æ—Ä–∏—è 1 - –ö–∞—Ç–µ–≥–æ—Ä–∏—è 2 - ..."
    - –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ (–≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è)
    """
    if not line_value:
        return []
    parts = [p.strip() for p in line_value.split("-")]
    return [p for p in parts if p]


def extract_code_blocks(lines: List[str], start_index: int, end_index: int) -> List[Dict[str, str]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å–µ–∫—Ü–∏–∏.
    - –ö–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã —Ç—Ä–æ–π–Ω—ã–º–∏ –±—ç–∫—Ç–∏–∫–∞–º–∏ ```...```
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –ª—é–±–æ–π —è–∑—ã–∫ (–≤–∫–ª—é—á–∞—è "c++", "tsx" –∏ —Ç.–ø.)
    - –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π: {"lang": <—è–∑—ã–∫ –∏–ª–∏ ''>, "code": <—Ç–µ–∫—Å—Ç –∫–æ–¥–∞>}
    """
    blocks = []
    i = start_index
    in_code = False
    cur_lang = ""
    cur_lines = []

    while i < end_index:
        line = lines[i]

        if not in_code:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞ –∫–æ–¥–∞: ```lang
            m = RE_CODE_FENCE_START.match(line)
            if m:
                in_code = True
                cur_lang = (m.group("lang") or "").strip()
                cur_lines = []
            # –µ—Å–ª–∏ –Ω–µ –Ω–∞—á–∞–ª–æ –∫–æ–¥–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –∏–¥—ë–º –¥–∞–ª—å—à–µ
        else:
            # –ú—ã –≤–Ω—É—Ç—Ä–∏ –∫–æ–¥–∞ ‚Äî –∏—â–µ–º –∫–æ–Ω–µ—Ü ```
            if RE_CODE_FENCE_END.match(line):
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±–ª–æ–∫
                blocks.append({"lang": cur_lang, "code": "".join(cur_lines)})
                in_code = False
                cur_lang = ""
                cur_lines = []
            else:
                # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞
                cur_lines.append(line)

        i += 1

    return blocks


def parse_markdown_file(path: Path) -> List[Dict]:
    """
    –†–∞–∑–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω .md —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π.
    –°–µ–∫—Ü–∏—è ‚Äî —ç—Ç–æ –±–ª–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞ "## <–∫–ª—é—á>".
    –°—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏:
      - —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ ===== / ----- (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
      - categories: ...
      - aliases: ...
    –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–µ–∫—Ü–∏–∏ ‚Äî –≤—Å—ë –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ "## " –∏–ª–∏ –∫–æ–Ω—Ü–∞ —Ñ–∞–π–ª–∞.

    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏:
      display_key, key, tokens, categories, aliases, file_path, start_line, markdown, code_blocks
    """
    text = safe_read_text(path)
    lines = text.splitlines(keepends=True)

    sections = []
    current_idx = 0
    n = len(lines)

    # –ù–∞–π–¥—ë–º –≤—Å–µ –∏–Ω–¥–µ–∫—Å—ã —Å—Ç—Ä–æ–∫, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å–µ–∫—Ü–∏—è (## ...)
    header_positions = []
    for idx, line in enumerate(lines):
        if RE_SECTION_HEADER.match(line):
            header_positions.append(idx)

    # –î–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ –≤—ã–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å–µ–∫—Ü–∏–∏
    for si, start_line_idx in enumerate(header_positions):
        # –ö–æ–Ω–µ—Ü —Å–µ–∫—Ü–∏–∏ ‚Äî –ª–∏–±–æ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –ª–∏–±–æ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
        end_line_idx = header_positions[si + 1] if si + 1 < len(header_positions) else n

        # –ü–∞—Ä—Å–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        header_match = RE_SECTION_HEADER.match(lines[start_line_idx])
        display_key = header_match.group("key").strip()
        key = normalize_key(display_key)
        tokens = tokenize_key(display_key)

        # –ü–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –º–æ–≥—É—Ç –∏–¥—Ç–∏:
        # - —Å—Ç—Ä–æ–∫–∞ ===== –∏–ª–∏ -----
        # - categories: ...
        # - aliases: ...
        # –ü—Ä–∏—á—ë–º –ø–æ—Ä—è–¥–æ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±—ã–º, –Ω–æ –æ–±—ã—á–Ω–æ ‚Äî —Å–ø–µ—Ä–≤–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
        i = start_line_idx + 1
        seen_categories = []
        seen_aliases = []

        # –î–≤–∏–∂–µ–º—Å—è –≤–Ω–∏–∑, –ø—Ä–æ–ø—É—Å–∫–∞—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –∏ —Å–æ–±–∏—Ä–∞—è categories/aliases
        while i < end_line_idx:
            s = lines[i]
            # –ï—Å–ª–∏ —ç—Ç–æ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å, –Ω–æ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ
            if RE_OPTIONAL_SEPARATOR.match(s):
                i += 1
                continue

            mc = RE_CATEGORIES.match(s)
            if mc:
                seen_categories = parse_categories(mc.group("cats"))
                i += 1
                continue

            ma = RE_ALIASES.match(s)
            if ma:
                seen_aliases = parse_aliases(ma.group("als"))
                i += 1
                continue

            # –ö–∞–∫ —Ç–æ–ª—å–∫–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Å—Ç—Ä–æ–∫—É, –Ω–µ –ø–æ–¥–ø–∞–¥–∞—é—â—É—é –ø–æ–¥ —ç—Ç–∏ –∫–µ–π—Å—ã ‚Äî –≤—ã—Ö–æ–¥–∏–º
            break

        # markdown —Å–µ–∫—Ü–∏–∏ ‚Äî —ç—Ç–æ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –æ—Ç —Å—Ç—Ä–æ–∫–∏ i –¥–æ end_line_idx
        md_text = "".join(lines[i:end_line_idx])

        # –í—ã—Ç–∞—â–∏–º –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ –∏–∑ –≤—Å–µ–π —Å–µ–∫—Ü–∏–∏
        code_blocks = extract_code_blocks(lines, i, end_line_idx)

        sections.append({
            "display_key": display_key,
            "key": key,
            "tokens": tokens,
            "categories": seen_categories,
            "aliases": seen_aliases,
            "file_path": str(path),
            "start_line": start_line_idx + 1,  # –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º 1-based
            "markdown": md_text,
            "code_blocks": code_blocks,
        })

    return sections


def scan_docs(root: Path) -> Tuple[List[Dict], Dict[str, List[Dict]]]:
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫—É root, –∏–≥–Ω–æ—Ä–∏—Ä—É—è —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ .md —Ñ–∞–π–ª–∞ –ø–∞—Ä—Å–∏–º —Å–µ–∫—Ü–∏–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º:
      - flat_sections: –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–µ–∫—Ü–∏–π
      - file_to_sections: —Å–ª–æ–≤–∞—Ä—å {–ø—É—Ç—å_—Ñ–∞–π–ª–∞: [—Å–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞]}
    """
    flat_sections: List[Dict] = []
    file_to_sections: Dict[str, List[Dict]] = {}

    for dirpath, dirnames, filenames in os.walk(root):
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–∞–ø–∫–∏ –Ω–∞ –º–µ—Å—Ç–µ (—á—Ç–æ–±—ã os.walk –Ω–µ –∑–∞—Ö–æ–¥–∏–ª –≤ –Ω–∏—Ö)
        dirnames[:] = [d for d in dirnames if d not in IGNORED_DIRS]

        for name in filenames:
            if not name.lower().endswith(".md"):
                continue
            path = Path(dirpath) / name
            try:
                secs = parse_markdown_file(path)
                if secs:
                    flat_sections.extend(secs)
                    file_to_sections[str(path)] = secs
            except Exception as e:
                # –ï—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∞–π–ª –Ω–µ —Ä–∞–∑–æ–±—Ä–∞–ª—Å—è ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–æ–æ–±—â–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å –∏ –ø—Ä–æ–¥–æ–ª–∂–∏–º
                print(f"[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å {path}: {e}", file=sys.stderr)

    return flat_sections, file_to_sections


# =========================
# 4) –§—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞
# =========================

def build_search_index(sections: List[Dict]) -> Dict:
    """
    –ì–æ—Ç–æ–≤–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:
    - keys -> —Å–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π (–∫–ª—é—á–∏ –º–æ–≥—É—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö)
    - alias_map -> alias -> —Å–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π
    - flat —Å–ø–∏—Å–∫–∏ –¥–ª—è fuzzy (–≤—Å–µ –∫–ª—é—á–∏ –∏ –≤—Å–µ –∞–ª–∏–∞—Å—ã)
    """
    key_map: Dict[str, List[Dict]] = {}
    alias_map: Dict[str, List[Dict]] = {}
    all_keys = []
    all_aliases = []

    for s in sections:
        key_map.setdefault(s["key"], []).append(s)
        for a in s["aliases"]:
            alias_map.setdefault(a, []).append(s)

        if s["key"] not in all_keys:
            all_keys.append(s["key"])
        for a in s["aliases"]:
            if a not in all_aliases:
                all_aliases.append(a)

    return {
        "key_map": key_map,
        "alias_map": alias_map,
        "all_keys": all_keys,
        "all_aliases": all_aliases,
        "sections": sections,
    }


def search_sections(index: Dict, query: str) -> Tuple[Optional[Dict], List[Dict]]:
    """
    –ì–ª–∞–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º:
    1) –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–∞ (key == query)
    2) –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞–ª–∏–∞—Å—É
    3) –ü–æ–¥—Å—Ç—Ä–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ key –∏–ª–∏ –∞–ª–∏–∞—Å–∞—Ö
    4) –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º (—Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
    5) Fuzzy-–ø–æ–∏—Å–∫ (difflib) –ø–æ –∫–ª—é—á–∞–º –∏ –∞–ª–∏–∞—Å–∞–º

    –í–æ–∑–≤—Ä–∞—â–∞–µ–º (section_or_None, candidates_list).
    - –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ.
    - –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None –∏ —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (UI –ø—Ä–µ–¥–ª–æ–∂–∏—Ç –≤—ã–±—Ä–∞—Ç—å).
    - –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî candidates –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.
    """
    q = normalize_key(query)
    if not q:
        return None, []

    key_map = index["key_map"]
    alias_map = index["alias_map"]
    all_sections = index["sections"]

    # 1) –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–∞ ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–µ–µ –≤—Å–µ–≥–æ
    if q in key_map:
        candidates = key_map[q]
        # –ï—Å–ª–∏ –æ–¥–Ω–∞ —Å–µ–∫—Ü–∏—è ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ—ë —Å—Ä–∞–∑—É, –∏–Ω–∞—á–µ –æ—Ç–¥–∞—ë–º —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        if len(candidates) == 1:
            return candidates[0], candidates
        else:
            # —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∏–¥—É—Ç –ø–µ—Ä–≤—ã–º–∏
            return None, candidates

    # 2) –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∞–ª–∏–∞—Å—É
    if q in alias_map:
        candidates = alias_map[q]
        if len(candidates) == 1:
            return candidates[0], candidates
        else:
            return None, candidates

    # 3) –ü–æ–¥—Å—Ç—Ä–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: –∏—â–µ–º –≤ key –∏ –∞–ª–∏–∞—Å–∞—Ö
    sub_candidates: List[Dict] = []
    for s in all_sections:
        if q in s["key"]:
            sub_candidates.append(s)
            continue
        if any(q in a for a in s["aliases"]):
            sub_candidates.append(s)

    if sub_candidates:
        # –ï—Å–ª–∏ —Ä–æ–≤–Ω–æ –æ–¥–Ω–∞ ‚Äî –≤–µ—Ä–Ω—ë–º –µ—ë, –∏–Ω–∞—á–µ —Å–ø–∏—Å–æ–∫
        if len(sub_candidates) == 1:
            return sub_candidates[0], sub_candidates
        else:
            return None, sub_candidates

    # 4) –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º:
    q_tokens = tokenize_key(q)  # —Ç–æ–∫–µ–Ω—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
    token_candidates = []
    if q_tokens:
        for s in all_sections:
            # –µ—Å–ª–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ–ø—É—Å—Ç–æ–µ ‚Äî —Å—á–∏—Ç–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º
            if set(q_tokens) & set(s["tokens"]):
                token_candidates.append(s)

    if token_candidates:
        if len(token_candidates) == 1:
            return token_candidates[0], token_candidates
        else:
            return None, token_candidates

    # 5) Fuzzy ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º difflib.get_close_matches –ø–æ –∫–ª—é—á–∞–º –∏ –ø–æ –∞–ª–∏–∞—Å–∞–º
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å—Ä–µ–¥–∏ –∫–ª—é—á–µ–π
    fuzzy_keys = difflib.get_close_matches(q, index["all_keys"], n=8, cutoff=0.6)
    fuzzy_aliases = difflib.get_close_matches(q, index["all_aliases"], n=8, cutoff=0.6)

    fuzzy_candidates: List[Dict] = []
    for fk in fuzzy_keys:
        fuzzy_candidates.extend(key_map.get(fk, []))
    for fa in fuzzy_aliases:
        fuzzy_candidates.extend(alias_map.get(fa, []))

    # –£–±–µ—Ä—ë–º –¥—É–±–ª–∏ (–æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Å–µ–∫—Ü–∏–∏ –º–æ–≥–ª–∏ –ø–æ–ø–∞—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑)
    seen = set()
    unique = []
    for s in fuzzy_candidates:
        nid = (s["file_path"], s["start_line"])
        if nid not in seen:
            seen.add(nid)
            unique.append(s)

    if unique:
        if len(unique) == 1:
            return unique[0], unique
        else:
            return None, unique

    # –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏
    return None, []


# =========================
# 5) –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤ –¥–ª—è UI
# =========================

def build_category_tree(sections: List[Dict], docs_root: Path) -> Dict:
    """
    –°—Ç—Ä–æ–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –¥–µ—Ä–µ–≤–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π:
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞:
    {
      "–ö–∞—Ç–µ–≥–æ—Ä–∏—è 1": {
          "_children": { ... },
          "_sections": [ ... —Å–µ–∫—Ü–∏–∏ –±–µ–∑ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π ... ]
      },
      ...
    }
    –ò –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π ‚Äî –ø–æ–ª–æ–∂–∏–º –≤ –∫–æ—Ä–µ–Ω—å "_sections".

    –í–Ω—É—Ç—Ä–∏ —É–∑–ª–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "_sections" ‚Äî —Å–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π, —Ä–µ–∞–ª—å–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö –≤ –¥–µ—Ä–µ–≤–µ (–∫–∞–∫ "¬ß –∫–ª—é—á (rel_path)").
    """
    tree = {"_sections": []}

    for s in sections:
        cats = s["categories"]
        if not cats:
            tree["_sections"].append(s)
            continue

        # –ò–¥—ë–º –ø–æ –ø—É—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        node = tree
        for c in cats:
            if c not in node:
                node[c] = {"_sections": []}
            node = node[c]
        node["_sections"].append(s)

    return tree


def build_files_tree(docs_root: Path) -> Dict:
    """
    –°—Ç—Ä–æ–∏–º –ø—Ä–æ—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–µ—Ä–µ–≤–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è UI:
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
    {
      "name": <–∏–º—è –ø–∞–ø–∫–∏>,
      "path": <–∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å>,
      "dirs": [subtree...],
      "files": [ {"name": fname, "path": abspath}, ... ]
    }
    –¢–æ–ª—å–∫–æ –¥–ª—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –≤–Ω—É—Ç—Ä–∏ docs_root, –∏–≥–Ω–æ—Ä–∏—Ä—É—è —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏.
    """
    def walk_dir(path: Path) -> Dict:
        node = {
            "name": path.name,
            "path": str(path),
            "dirs": [],
            "files": []
        }
        try:
            for entry in sorted(path.iterdir(), key=lambda p: (p.is_file(), p.name.lower())):
                if entry.is_dir():
                    if entry.name in IGNORED_DIRS:
                        continue
                    node["dirs"].append(walk_dir(entry))
                else:
                    if entry.name.lower().endswith(".md"):
                        node["files"].append({"name": entry.name, "path": str(entry)})
        except PermissionError:
            pass
        return node

    return walk_dir(docs_root)


# =========================
# 6) –£—Ç–∏–ª–∏—Ç—ã
# =========================

def open_in_system(filepath: str):
    """
    –û—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª —à—Ç–∞—Ç–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–æ–π –û–°.
    –ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ:
      - Windows: os.startfile
      - macOS: open
      - Linux: xdg-open
    """
    try:
        if sys.platform.startswith("win"):
            os.startfile(filepath)  # type: ignore[attr-defined]
        elif sys.platform == "darwin":
            subprocess.run(["open", filepath], check=False)
        else:
            subprocess.run(["xdg-open", filepath], check=False)
    except Exception as e:
        messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª:\n{e}")


def ensure_sample_docs(docs_root: Path):
    """
    –ï—Å–ª–∏ –ø–∞–ø–∫–∞ docs –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ–∑–¥–∞–¥–∏–º.
    –ï—Å–ª–∏ –Ω–µ—Ç html.md –∏ css.md ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏:
    - –º–∏–Ω–∏–º—É–º 2‚Äì3 —Å–µ–∫—Ü–∏–∏
    - —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ —Å–µ–∫—Ü–∏—è —Å aliases
    - —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –ø—É—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    - —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–æ–¥–æ–≤—ã–º–∏ –±–ª–æ–∫–∞–º–∏
    """
    docs_root.mkdir(parents=True, exist_ok=True)

    html_path = docs_root / "html.md"
    css_path = docs_root / "css.md"

    if not html_path.exists():
        html_path.write_text("""---
## ul-ol-li
==========================
HTML - –°–ø–∏—Å–∫–∏
aliases: lists, bullets
–û–ø–∏—Å–∞–Ω–∏–µ: –ü—Ä–∏–º–µ—Ä—ã –Ω–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã—Ö –∏ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤ –≤ HTML.

```html
<ul>
  <li>HTML</li>
  <li>CSS</li>
  <li>JavaScript</li>
</ul>
